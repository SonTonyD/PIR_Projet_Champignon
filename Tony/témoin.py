# -*- coding: utf-8 -*-
"""Témoin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tLXU2_VQAwxY8eZBiJ_xsUmLSNciRXpR
"""

!pip install split-folders

# Commented out IPython magic to ensure Python compatibility.
# %rm -rf sample_data

# Commented out IPython magic to ensure Python compatibility.
# %rm -rf saved_model

# Commented out IPython magic to ensure Python compatibility.
# %rm -rf Mushrooms

!mkdir Mushrooms
!mkdir Mushrooms/input_dataset
!mkdir Mushrooms/input_dataset/Boletus
!mkdir Mushrooms/input_dataset/Amanita

import splitfolders
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

rmdir /content/Mushrooms/input_dataset/.ipynb_checkpoints

"""**Mettre les données**



"""

def split_datas(ratio):
    """ This function allows to split input data in 3 differents dir : train/test/val according the ratio
        @ratio (0.6, 0.2, 0.2)
    """

    input_folder = "Mushrooms/input_dataset"
    output_folder = "Mushrooms/processed_Data"
    splitfolders.ratio(input_folder, output_folder, seed=42, ratio=ratio)

split_datas((0.75, 0.15, 0.1))

IMG_HEIGHT, IMG_WIDTH = (224, 224)  # height width
BATCH_SIZE = 32  # nombre d'image processed en meme temps  (https://arxiv.org/pdf/1404.5997.pdf)
TRAIN_DIR = r"Mushrooms/processed_Data/train"
VALIDATION_DIR = r"Mushrooms/processed_Data/val"
TEST_DIR = r"Mushrooms/processed_Data/test"
EPOCHS = 20
pretrain = "inception_v3"
preprocess_input = getattr(__import__("tensorflow.keras.applications."+pretrain, fromlist=["preprocess_input"]), "preprocess_input")
model_name = pretrain+"/e"+str(EPOCHS)+"_b"+str(BATCH_SIZE)+"_boolean_bolete"
print("Save model to : saved_model/{}.h5".format(model_name))

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # preprocess input from RESNET50, convert RGB to BGR
    shear_range=0.2,  # image will be distorted along an axis
    zoom_range=0.2,  # zoom de l'image
    horizontal_flip=True,  # allow horizontal flip
    vertical_flip=True,  # allow vertical flip
    validation_split=0.2  # Float. Fraction of images reserved for validation (strictly between 0 and 1).
)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="training"
)

valid_generator = train_datagen.flow_from_directory(
    VALIDATION_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="validation"
)
test_generator = train_datagen.flow_from_directory(
    TEST_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=1,
    class_mode="categorical",
    subset="validation"
)


data_augmentation = Sequential(
  [
    layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),  # flip vertical ou horizontal
    layers.experimental.preprocessing.RandomRotation(0.2),  # range : [-20% * 2pi, 20% * 2pi].
    layers.experimental.preprocessing.RandomZoom(0.1),  # random zoom

  ]
)

if pretrain == "resnet50":
    base_model = ResNet50(include_top=False, weights='imagenet')
elif pretrain == "vgg16":
    base_model = VGG16(include_top=False, weights='imagenet')
else:
    base_model = InceptionV3(include_top=False, weights='imagenet')

for layer in base_model.layers:
    layer.trainable = False  # layer from ResNet network won't be trained

model = Sequential()
model.add(data_augmentation)
model.add(base_model)  # We don't use fully connected layer
model.add(Flatten())  # Need to flatten the cnn
model.add(Dropout(0.3))
model.add(Dense(2048, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(2048, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(1024, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(512, activation="relu"))
model.add(Dropout(0.2))
model.add(Dense(512, activation="relu"))
model.add(Dropout(0.1))
model.add(Dense(256, activation="relu"))
model.add(Dense(train_generator.num_classes, activation='softmax'))
    
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=['accuracy'])
history = model.fit(train_generator, validation_data=valid_generator, epochs=EPOCHS)
model.save("saved_model/"+model_name+".h5")
model.summary()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

import csv
values = [loss, acc, val_loss, val_acc]
with open('resultat_temoin.csv','w',newline='') as csv_file:
  writer = csv.writer(csv_file, delimiter=';')
  writer.writerow(values)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sn
import tensorflow as tf
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

class_names = list(test_generator.class_indices.keys())

test_generator = train_datagen.flow_from_directory(
    TEST_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=1,
    shuffle=True,
    class_mode="categorical",
    subset="validation"
)

list(test_generator.class_indices.keys())

def get_loss_acc():
    test_loss, test_acc = model.evaluate(test_generator, verbose=2)
    print("Accuracy : {}".format(test_acc))
    print("Loss : {}".format(test_loss))

def plot_image(predictions_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img.astype("uint8"))

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(predictions_array, true_label):
  plt.grid(False)
  plt.xticks(range(len(predictions_array)))
  plt.yticks([])
  thisplot = plt.bar(range(len(predictions_array)), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = predictions_array.argmax()

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

def show_matrix():

    filenames = test_generator.filenames
    nb_samples = len(test_generator)
    y_prob=[]
    y_act=[]
    test_generator.reset()
    for _ in range(nb_samples):
        X_test, Y_test = test_generator.next()
        y_prob.append(model.predict(X_test))
        y_act.append(Y_test)

    predicted_class = [list(test_generator.class_indices.keys())[i.argmax()] for i in y_prob]
    actual_class = [list(test_generator.class_indices.keys())[i.argmax()] for i in y_act]

    out_df = pd.DataFrame(np.vstack([predicted_class, actual_class]).T, columns=["predicted_class", "actual_class"])
    confusion_matrix = pd.crosstab(out_df["actual_class"], out_df["predicted_class"], rownames=["Actual"], colnames=["Predicted"], normalize="columns")

    sn.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt='.2%', cmap='Blues')
    plt.show()
    print('test accuracy : {}'.format((np.diagonal(confusion_matrix).sum()/confusion_matrix.sum().sum()*100)))
    

def show_first_picture(col,rows):
    num_rows = rows
    num_cols = col
    num_images = num_rows * num_cols
    plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))
    for i in range(num_images):
        preimg, lbl = test_generator.next()
        img = 127 + preimg[0]
        label = lbl.argmax()
        prediction = model.predict(preimg)[0]
        plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)
        plot_image(prediction, label, img)
        plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)
        plot_value_array(prediction, label)
    plt.tight_layout()
    plt.show()

show_matrix()
show_first_picture(5,8)